{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\n\nprint(os.listdir(\"../input\"))\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', -1)\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['Hindi_English_Truncated_Corpus.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"lines=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['source'].value_counts()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"tides        50000\nted          39881\nindic2012    37726\nName: source, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines[lines['source']=='ted']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head(20)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   source                                                            english_sentence                                                        hindi_sentence\n0   ted    politicians do not have permission to do what needs to be done.             राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n1   ted    I'd like to tell you about one such child,                                  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                  \n3   ted    what we really mean is that they're bad at not paying attention.            हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                      \n7   ted    And who are we to say, even, that they are wrong                            और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                    \n13  ted    So there is some sort of justice                                            तो वहाँ न्याय है                                                    \n23  ted    This changed slowly                                                         धीरे धीरे ये सब बदला                                                \n26  ted    were being produced.                                                        उत्पन्न नहीं कि जाती थी.                                            \n30  ted    And you can see, this LED is going to glow.                                 और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।                        \n32  ted    to turn on the lights or to bring him a glass of water,                     लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,                     \n35  ted    Can you imagine saying that?                                                क्या आप ये कल्पना कर सकते है                                        \n37  ted    Three: this is a good road in - right near where our factory is located.    तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षाकृत बेहतर सडक है।     \n39  ted    What's going on?”                                                           क्या हो रहा है ये?”                                                 \n42  ted    There are also financial reforms in rural China.                            ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।                           \n49  ted    the family planning started in Vietnam and they went for smaller families.  वियतनाम में परिवार योजना शुरू हो गई और उनके परिवार छोटे होने लगे।   \n51  ted    I mean, at that time, trust me,                                             मेरा मतलब, उस समय, सही मानिए,                                       \n53  ted    Not only that,                                                              बस वही नहीं,                                                        \n55  ted    humans destroyed the commons that they depended on.                         मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।     \n56  ted    Almost goes to E, but otherwise the play would be over.                     रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.         \n63  ted    So I want to share with you a couple key insights                           मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ                       \n66  ted    Many countries in the [unclear], they need legitimacy.                      [अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चाहिए.                  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ted</td>\n      <td>politicians do not have permission to do what needs to be done.</td>\n      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ted</td>\n      <td>I'd like to tell you about one such child,</td>\n      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ted</td>\n      <td>what we really mean is that they're bad at not paying attention.</td>\n      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ted</td>\n      <td>And who are we to say, even, that they are wrong</td>\n      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ted</td>\n      <td>So there is some sort of justice</td>\n      <td>तो वहाँ न्याय है</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ted</td>\n      <td>This changed slowly</td>\n      <td>धीरे धीरे ये सब बदला</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>ted</td>\n      <td>were being produced.</td>\n      <td>उत्पन्न नहीं कि जाती थी.</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ted</td>\n      <td>And you can see, this LED is going to glow.</td>\n      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ted</td>\n      <td>to turn on the lights or to bring him a glass of water,</td>\n      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>ted</td>\n      <td>Can you imagine saying that?</td>\n      <td>क्या आप ये कल्पना कर सकते है</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ted</td>\n      <td>Three: this is a good road in - right near where our factory is located.</td>\n      <td>तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षाकृत बेहतर सडक है।</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ted</td>\n      <td>What's going on?”</td>\n      <td>क्या हो रहा है ये?”</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>ted</td>\n      <td>There are also financial reforms in rural China.</td>\n      <td>ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>ted</td>\n      <td>the family planning started in Vietnam and they went for smaller families.</td>\n      <td>वियतनाम में परिवार योजना शुरू हो गई और उनके परिवार छोटे होने लगे।</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>ted</td>\n      <td>I mean, at that time, trust me,</td>\n      <td>मेरा मतलब, उस समय, सही मानिए,</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>ted</td>\n      <td>Not only that,</td>\n      <td>बस वही नहीं,</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>ted</td>\n      <td>humans destroyed the commons that they depended on.</td>\n      <td>मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>ted</td>\n      <td>Almost goes to E, but otherwise the play would be over.</td>\n      <td>रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>ted</td>\n      <td>So I want to share with you a couple key insights</td>\n      <td>मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>ted</td>\n      <td>Many countries in the [unclear], they need legitimacy.</td>\n      <td>[अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चाहिए.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(lines).sum()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"source              0\nenglish_sentence    0\nhindi_sentence      0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines[~pd.isnull(lines['english_sentence'])]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.drop_duplicates(inplace=True)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Let us pick any 25000 rows from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines.sample(n=25000,random_state=42)\nlines.shape","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(25000, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lowercase all characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove quotes\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude = set(string.punctuation) # Set of all special characters\n# Remove all the special characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove all numbers from text\nremove_digits = str.maketrans('', '', digits)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n\n# Remove extra spaces\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add start and end tokens to target sequences\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                           \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                 \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                          \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Get English and Hindi Vocabulary\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_hindi_words=set()\nfor hin in lines['hindi_sentence']:\n    for word in hin.split():\n        if word not in all_hindi_words:\n            all_hindi_words.add(word)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_eng_words)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"14030"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_hindi_words)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"17540"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.head()","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence  length_eng_sentence  length_hin_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                   11                   16                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                             2                    5                  \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                   7                    8                  \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                            4                    6                  \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END  16                   20                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n      <td>11</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines[lines['length_eng_sentence']>30].shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(0, 5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines[lines['length_eng_sentence']<=20]\nlines=lines[lines['length_hin_sentence']<=20]","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.shape","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"(24774, 5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\nprint(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))","execution_count":24,"outputs":[{"output_type":"stream","text":"maximum length of Hindi Sentence  20\nmaximum length of English Sentence  20\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length_src=max(lines['length_hin_sentence'])\nmax_length_tar=max(lines['length_eng_sentence'])","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_hindi_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_hindi_words)\nnum_encoder_tokens, num_decoder_tokens","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(14030, 17540)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_decoder_tokens += 1 #for zero padding\n","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines = shuffle(lines)\nlines.head(10)","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"       source                                                         english_sentence                                                                hindi_sentence  length_eng_sentence  length_hin_sentence\n41845   ted    wk um                                                                    START_ व क अम _END                                                            2                    5                  \n117510  ted    i dont know where we are now                                             START_ मुझे नहीं पता है हम अब कहाँ हैं _END                                   7                    10                 \n68119   ted    how to get from point a to point b                                       START_ कैसे पॉइंट अ से पॉइंट बी तक पोहोच सकते है _END                         9                    12                 \n51706   ted    and i could just imagine the committees                                  START_ और मैं अभी ये कल्पना कर सकता हूँ कि संस्थाएं _END                      7                    12                 \n124188  ted    and yet why should there be so much variation in quality and in service  START_ तो फिरे कोई वजह नहीं कि गुणवत्ता और सेवा में इतना ज्यादा फर्क हो _END  14                   16                 \n61617   ted    this onceinalifetime discovery                                           START_ बहुत लंबे समय के बाद हमने खोज की है _END                               3                    11                 \n33200   ted    whos raised to believe that that mountain is an apu spirit               START_ पालनपोषण करते हुए उसे यह बताए कि _END                                  11                   9                  \n29951   ted    she raised her hand and she says to me in broken tamil and english       START_ उसने हाथ उठाया और उसने मुझे टूटी हुई तमिल और अंग्रेज़ी में कहा _END    14                   15                 \n50064   ted    who bring you free refills without asking                                START_ कुछ कहे बिना ही मुफ़त में ज्यादा सर्व कर देना _END                     7                    12                 \n9566    ted    so lets compare the old world with the new world                         START_ तो नई दुनिया के साथ पुरानी दुनिया की तुलना करते हैं _END               10                   13                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41845</th>\n      <td>ted</td>\n      <td>wk um</td>\n      <td>START_ व क अम _END</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>117510</th>\n      <td>ted</td>\n      <td>i dont know where we are now</td>\n      <td>START_ मुझे नहीं पता है हम अब कहाँ हैं _END</td>\n      <td>7</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>68119</th>\n      <td>ted</td>\n      <td>how to get from point a to point b</td>\n      <td>START_ कैसे पॉइंट अ से पॉइंट बी तक पोहोच सकते है _END</td>\n      <td>9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>51706</th>\n      <td>ted</td>\n      <td>and i could just imagine the committees</td>\n      <td>START_ और मैं अभी ये कल्पना कर सकता हूँ कि संस्थाएं _END</td>\n      <td>7</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>124188</th>\n      <td>ted</td>\n      <td>and yet why should there be so much variation in quality and in service</td>\n      <td>START_ तो फिरे कोई वजह नहीं कि गुणवत्ता और सेवा में इतना ज्यादा फर्क हो _END</td>\n      <td>14</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>61617</th>\n      <td>ted</td>\n      <td>this onceinalifetime discovery</td>\n      <td>START_ बहुत लंबे समय के बाद हमने खोज की है _END</td>\n      <td>3</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>33200</th>\n      <td>ted</td>\n      <td>whos raised to believe that that mountain is an apu spirit</td>\n      <td>START_ पालनपोषण करते हुए उसे यह बताए कि _END</td>\n      <td>11</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>29951</th>\n      <td>ted</td>\n      <td>she raised her hand and she says to me in broken tamil and english</td>\n      <td>START_ उसने हाथ उठाया और उसने मुझे टूटी हुई तमिल और अंग्रेज़ी में कहा _END</td>\n      <td>14</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>50064</th>\n      <td>ted</td>\n      <td>who bring you free refills without asking</td>\n      <td>START_ कुछ कहे बिना ही मुफ़त में ज्यादा सर्व कर देना _END</td>\n      <td>7</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9566</th>\n      <td>ted</td>\n      <td>so lets compare the old world with the new world</td>\n      <td>START_ तो नई दुनिया के साथ पुरानी दुनिया की तुलना करते हैं _END</td>\n      <td>10</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Split the data into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = lines['english_sentence'], lines['hindi_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\nX_train.shape, X_test.shape","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"((19819,), (4955,))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Let us save this data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoder-Decoder Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_dim=300","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","execution_count":35,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":38,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 300)    4209000     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 17541)  5279841     lstm_2[0][0]                     \n==================================================================================================\nTotal params: 16,193,541\nTrainable params: 16,193,541\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 100","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)","execution_count":40,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/100\n154/154 [==============================] - 70s 454ms/step - loss: 6.4323 - val_loss: 6.1006\nEpoch 2/100\n154/154 [==============================] - 63s 407ms/step - loss: 5.8455 - val_loss: 5.7498\nEpoch 3/100\n154/154 [==============================] - 62s 401ms/step - loss: 5.4862 - val_loss: 5.5902\nEpoch 4/100\n154/154 [==============================] - 61s 396ms/step - loss: 5.2445 - val_loss: 5.4641\nEpoch 5/100\n154/154 [==============================] - 61s 394ms/step - loss: 5.0416 - val_loss: 5.4021\nEpoch 6/100\n154/154 [==============================] - 61s 396ms/step - loss: 4.8561 - val_loss: 5.3445\nEpoch 7/100\n154/154 [==============================] - 61s 399ms/step - loss: 4.6837 - val_loss: 5.2780\nEpoch 8/100\n154/154 [==============================] - 61s 395ms/step - loss: 4.5214 - val_loss: 5.2521\nEpoch 9/100\n154/154 [==============================] - 61s 395ms/step - loss: 4.3683 - val_loss: 5.2312\nEpoch 10/100\n154/154 [==============================] - 61s 395ms/step - loss: 4.2204 - val_loss: 5.2224\nEpoch 11/100\n154/154 [==============================] - 61s 394ms/step - loss: 4.0776 - val_loss: 5.2265\nEpoch 12/100\n154/154 [==============================] - 61s 394ms/step - loss: 3.9394 - val_loss: 5.2091\nEpoch 13/100\n154/154 [==============================] - 61s 395ms/step - loss: 3.8054 - val_loss: 5.2194\nEpoch 14/100\n154/154 [==============================] - 61s 398ms/step - loss: 3.6752 - val_loss: 5.2347\nEpoch 15/100\n154/154 [==============================] - 61s 399ms/step - loss: 3.5455 - val_loss: 5.2580\nEpoch 16/100\n154/154 [==============================] - 61s 396ms/step - loss: 3.4231 - val_loss: 5.2661\nEpoch 17/100\n154/154 [==============================] - 61s 395ms/step - loss: 3.2998 - val_loss: 5.2843\nEpoch 18/100\n154/154 [==============================] - 61s 397ms/step - loss: 3.1794 - val_loss: 5.3274\nEpoch 19/100\n154/154 [==============================] - 62s 401ms/step - loss: 3.0620 - val_loss: 5.3606\nEpoch 20/100\n154/154 [==============================] - 61s 393ms/step - loss: 2.9477 - val_loss: 5.3994\nEpoch 21/100\n154/154 [==============================] - 61s 394ms/step - loss: 2.8356 - val_loss: 5.4558\nEpoch 22/100\n154/154 [==============================] - 64s 414ms/step - loss: 2.7253 - val_loss: 5.4893\nEpoch 23/100\n154/154 [==============================] - 63s 409ms/step - loss: 2.6155 - val_loss: 5.5261\nEpoch 24/100\n154/154 [==============================] - 61s 398ms/step - loss: 2.5095 - val_loss: 5.5748\nEpoch 25/100\n154/154 [==============================] - 61s 398ms/step - loss: 2.4096 - val_loss: 5.6252\nEpoch 26/100\n154/154 [==============================] - 61s 397ms/step - loss: 2.3124 - val_loss: 5.6676\nEpoch 27/100\n154/154 [==============================] - 61s 397ms/step - loss: 2.2152 - val_loss: 5.7372\nEpoch 28/100\n154/154 [==============================] - 61s 399ms/step - loss: 2.1215 - val_loss: 5.7658\nEpoch 29/100\n154/154 [==============================] - 61s 399ms/step - loss: 2.0329 - val_loss: 5.8122\nEpoch 30/100\n154/154 [==============================] - 63s 406ms/step - loss: 1.9429 - val_loss: 5.8493\nEpoch 31/100\n154/154 [==============================] - 61s 399ms/step - loss: 1.8554 - val_loss: 5.9019\nEpoch 32/100\n154/154 [==============================] - 61s 399ms/step - loss: 1.7711 - val_loss: 5.9493\nEpoch 33/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.6934 - val_loss: 5.9965\nEpoch 34/100\n154/154 [==============================] - 62s 402ms/step - loss: 1.6183 - val_loss: 6.0410\nEpoch 35/100\n154/154 [==============================] - 61s 399ms/step - loss: 1.5436 - val_loss: 6.0734\nEpoch 36/100\n154/154 [==============================] - 62s 401ms/step - loss: 1.4728 - val_loss: 6.1210\nEpoch 37/100\n154/154 [==============================] - 61s 398ms/step - loss: 1.4058 - val_loss: 6.1659\nEpoch 38/100\n154/154 [==============================] - 62s 403ms/step - loss: 1.3371 - val_loss: 6.2345\nEpoch 39/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.2736 - val_loss: 6.2816\nEpoch 40/100\n154/154 [==============================] - 61s 399ms/step - loss: 1.2125 - val_loss: 6.3137\nEpoch 41/100\n154/154 [==============================] - 61s 397ms/step - loss: 1.1556 - val_loss: 6.3710\nEpoch 42/100\n154/154 [==============================] - 61s 399ms/step - loss: 1.1032 - val_loss: 6.4158\nEpoch 43/100\n154/154 [==============================] - 61s 396ms/step - loss: 1.0536 - val_loss: 6.4452\nEpoch 44/100\n154/154 [==============================] - 61s 396ms/step - loss: 1.0057 - val_loss: 6.4944\nEpoch 45/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.9628 - val_loss: 6.5212\nEpoch 46/100\n154/154 [==============================] - 61s 396ms/step - loss: 0.9201 - val_loss: 6.5594\nEpoch 47/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.8794 - val_loss: 6.6087\nEpoch 48/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.8397 - val_loss: 6.6521\nEpoch 49/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.8059 - val_loss: 6.6626\nEpoch 50/100\n154/154 [==============================] - 61s 395ms/step - loss: 0.7701 - val_loss: 6.7048\nEpoch 51/100\n154/154 [==============================] - 61s 395ms/step - loss: 0.7363 - val_loss: 6.7256\nEpoch 52/100\n154/154 [==============================] - 61s 395ms/step - loss: 0.7028 - val_loss: 6.7388\nEpoch 53/100\n154/154 [==============================] - 61s 393ms/step - loss: 0.6739 - val_loss: 6.7854\nEpoch 54/100\n154/154 [==============================] - 61s 393ms/step - loss: 0.6457 - val_loss: 6.8153\nEpoch 55/100\n154/154 [==============================] - 61s 395ms/step - loss: 0.6148 - val_loss: 6.8493\nEpoch 56/100\n154/154 [==============================] - 61s 395ms/step - loss: 0.5886 - val_loss: 6.8551\nEpoch 57/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.5647 - val_loss: 6.9076\nEpoch 58/100\n153/154 [============================>.] - ETA: 0s - loss: 0.5439","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-b22c3ec5e69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_steps = val_samples//batch_size)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('nmt_weights.h5')","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nk=-1","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":45,"outputs":[{"output_type":"stream","text":"Input English sentence: you say it\nActual Hindi Translation:  अब तुम बोलो \nPredicted Hindi Translation:  तो आप ये कह सकते है \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":46,"outputs":[{"output_type":"stream","text":"Input English sentence: the words that are associated with that person\nActual Hindi Translation:  वो शब्द जो उस व्यक्ति से संबंद्धित हैं \nPredicted Hindi Translation:  उस शब्द जो कि हर व्यक्ति चीजों को सम्बन्ध \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":47,"outputs":[{"output_type":"stream","text":"Input English sentence: alexander a young macedonian\nActual Hindi Translation:  सिकंदर युवा मकदूनियन \nPredicted Hindi Translation:  सिकंदर युवा मकदूनियन \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":48,"outputs":[{"output_type":"stream","text":"Input English sentence: shes holding out that cheap kmart purse and she is wielding it\nActual Hindi Translation:  वो अपने सस्ते केमार्ट पर्स को आगे बढ़ाये हैं और उसका इस्तेमाल कर रही हैं \nPredicted Hindi Translation:  वो अपनी बेटी को उसके बारे में बहुत ज्यादा से अपे\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","execution_count":49,"outputs":[{"output_type":"stream","text":"Input English sentence: this is a work in process\nActual Hindi Translation:  यह काम अभी प्रक्रिया में है \nPredicted Hindi Translation:  यह काम अभी प्रक्रिया में है \n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}